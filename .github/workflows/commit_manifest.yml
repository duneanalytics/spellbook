name: Commit Manifest

on:
  workflow_dispatch:
  push:
    branches:
      - "main"

concurrency:
  group: ${{ github.workflow }}
  cancel-in-progress: true
      
jobs:
  commit_manifest:
    runs-on: [ self-hosted, linux, spellbook-trino-ci ]
    strategy:
      matrix:
        project: [ 'tokens', 'spellbook' ]
      max-parallel: 1

    steps:
    - uses: actions/setup-python@v3
    - name: Checkout main branch
      uses: actions/checkout@v2
      with:
        ref: main

    - name: Add git_sha to schema
      run: "/runner/change_schema.sh wizard"
    
    - name: Setup variables
      run: |
        echo "GIT_SHA=$(echo ${{ github.sha }} | tr - _ | cut -c1-7)" >> $GITHUB_ENV
        echo "PROFILE=--profiles-dir $HOME/.dbt --profile dunesql" >> $GITHUB_ENV
        if [[ "${{ matrix.project }}" == "tokens" ]]; then
          echo "PROJECT_DIR=tokens" >> $GITHUB_ENV
          echo "S3_LOCATION=s3://manifest-spellbook-dunesql/tokens" >> $GITHUB_ENV
        elif [[ "${{ matrix.project }}" == "spellbook" ]]; then
          echo "PROJECT_DIR=." >> $GITHUB_ENV
          echo "S3_LOCATION=s3://manifest-spellbook-dunesql/spellbook" >> $GITHUB_ENV
        fi

    - name: dbt dependencies
      working-directory: ${{env.PROJECT_DIR}}
      run: "dbt deps"
    
    - name: Run dbt debug on Trino if dunesql engine is used, and retry until cluster is available
      run: "./scripts/ensure_cluster.sh"
          
    - name: dbt compile to create prod manifest from main
      run: "dbt compile --target-path . $PROFILE --project-dir ${PROJECT_DIR}"

    - name: copy old manifest locally
      run: "aws s3 cp $S3_LOCATION/manifest.json $S3_LOCATION/previous_manifest.json"

    - name: upload git_sha versioned previous manifest (for manual catchup if jobs fail)
      run: "aws s3 cp $S3_LOCATION/manifest.json $S3_LOCATION/manifest_$GIT_SHA.json"

    - name: upload manifest
      run: "aws s3 cp $PROJECT_DIR/manifest.json $S3_LOCATION/manifest.json"